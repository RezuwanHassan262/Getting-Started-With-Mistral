{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d7f6058-d0d1-44af-b43a-cb4b06df03d8",
   "metadata": {},
   "source": [
    "# Prompting Capabilities \n",
    "\n",
    "- Note, you can try any of these prompts outside of this classroom, and without coding, by going to the chat interface [Le Chat](https://chat.mistral.ai/chat).\n",
    "  - You can sign up with a free account.\n",
    "  - Signing up for an account is **not** required to complete this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa37d97-10e4-425d-b852-15bd043662b9",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# !pip install mistralai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b3ac64-1295-4a0e-90ab-51c338c945f7",
   "metadata": {},
   "source": [
    "- Notice that it's \"mistralai\", and not \"mistral\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff393a84-303a-48ae-97fe-3551f524f733",
   "metadata": {},
   "source": [
    "### Load API key and helper function\n",
    "- Note: You can view or download the helper.py file by clicking on the \"Jupyter\" logo to access the file directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f6a5640-203a-4e7a-bc4c-4bfe78da4099",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from helper import load_mistral_api_key\n",
    "load_mistral_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e030d9c2-1ecb-4bf0-864d-9f96b41bd016",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I can assist with a wide range of tasks and provide information on various topics. Here are some things I can do:\\n\\n1. **Answer Questions**: I can provide information on a broad range of subjects, from general knowledge to specific queries.\\n2. **Explain Concepts**: I can help explain complex ideas in a simpler way.\\n3. **Provide Recommendations**: Whether it's a book, movie, recipe, or travel destination, I can offer suggestions.\\n4. **Help with Language**: I can assist with language translation, grammar checks, and writing assistance.\\n5. **Offer Study Help**: I can provide explanations for academic subjects, help with homework, and offer study tips.\\n6. **Give Advice**: I can offer general advice on various topics, though for specific or critical issues, it's always best to consult a professional.\\n7. **Engage in Conversation**: I can participate in casual conversations and provide companionship.\\n8. **Assist with Technical Issues**: I can help troubleshoot common technical problems and provide guidance on using software and tools.\\n9. **Plan and Organize**: I can help with planning events, creating schedules, and organizing tasks.\\n10. **Provide Entertainment**: I can tell jokes, share interesting facts, and even play simple text-based games.\\n\\nWhat do you need help with today?\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helper import mistral\n",
    "mistral(\"hello, what can you do?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98a29ef-4764-40b7-aed8-0e5d0502f985",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d71e9d1c-ca45-4d19-882c-07e077ea19ad",
   "metadata": {
    "height": 642
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "    You are a bank customer service bot. \n",
    "    Your task is to assess customer intent and categorize customer \n",
    "    inquiry after <<<>>> into one of the following predefined categories:\n",
    "    \n",
    "    card arrival\n",
    "    change pin\n",
    "    exchange rate\n",
    "    country support \n",
    "    cancel transfer\n",
    "    charge dispute\n",
    "    \n",
    "    If the text doesn't fit into any of the above categories, \n",
    "    classify it as:\n",
    "    customer service\n",
    "    \n",
    "    You will only respond with the predefined category. \n",
    "    Do not provide explanations or notes. \n",
    "    \n",
    "    ###\n",
    "    Here are some examples:\n",
    "    \n",
    "    Inquiry: How do I know if I will get my card, or if it is lost? I am concerned about the delivery process and would like to ensure that I will receive my card as expected. Could you please provide information about the tracking process for my card, or confirm if there are any indicators to identify if the card has been lost during delivery?\n",
    "    Category: card arrival\n",
    "    Inquiry: I am planning an international trip to Paris and would like to inquire about the current exchange rates for Euros as well as any associated fees for foreign transactions.\n",
    "    Category: exchange rate \n",
    "    Inquiry: What countries are getting support? I will be traveling and living abroad for an extended period of time, specifically in France and Germany, and would appreciate any information regarding compatibility and functionality in these regions.\n",
    "    Category: country support\n",
    "    Inquiry: Can I get help starting my computer? I am having difficulty starting my computer, and would appreciate your expertise in helping me troubleshoot the issue. \n",
    "    Category: customer service\n",
    "    ###\n",
    "    \n",
    "    <<<\n",
    "    Inquiry: {inquiry}\n",
    "    >>>\n",
    "    Category:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21d367f-cc2c-4857-abd5-d1f6a545ebc0",
   "metadata": {},
   "source": [
    "#### Ask Mistral to check the spelling and grammar of your prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "465a2ecd-e542-4863-96dc-29786c003799",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "response = mistral(f\"Please correct the spelling and grammar of \\\n",
    "this prompt and return a text that is the same prompt,\\\n",
    "with the spelling and grammar fixed: {prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "476f0db5-ba51-43ca-a4c4-dc2b072291ba",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the corrected version of the prompt:\n",
      "\n",
      "You are a bank customer service bot.\n",
      "Your task is to assess customer intent and categorize customer inquiry after <<<>>> into one of the following predefined categories:\n",
      "\n",
      "card arrival\n",
      "change pin\n",
      "exchange rate\n",
      "country support\n",
      "cancel transfer\n",
      "charge dispute\n",
      "\n",
      "If the text doesn't fit into any of the above categories,\n",
      "classify it as:\n",
      "customer service\n",
      "\n",
      "You will only respond with the predefined category.\n",
      "Do not provide explanations or notes.\n",
      "\n",
      "###\n",
      "Here are some examples:\n",
      "\n",
      "Inquiry: How do I know if I will get my card, or if it is lost? I am concerned about the delivery process and would like to ensure that I will receive my card as expected. Could you please provide information about the tracking process for my card, or confirm if there are any indicators to identify if the card has been lost during delivery?\n",
      "Category: card arrival\n",
      "\n",
      "Inquiry: I am planning an international trip to Paris and would like to inquire about the current exchange rates for Euros as well as any associated fees for foreign transactions.\n",
      "Category: exchange rate\n",
      "\n",
      "Inquiry: What countries are getting support? I will be traveling and living abroad for an extended period of time, specifically in France and Germany, and would appreciate any information regarding compatibility and functionality in these regions.\n",
      "Category: country support\n",
      "\n",
      "Inquiry: Can I get help starting my computer? I am having difficulty starting my computer, and would appreciate your expertise in helping me troubleshoot the issue.\n",
      "Category: customer service\n",
      "\n",
      "###\n",
      "\n",
      "<<<\n",
      "Inquiry: {inquiry}\n",
      ">>>\n",
      "Category:\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27bbf68-a0bc-4e8a-bb6b-8ae20f3f2e2d",
   "metadata": {},
   "source": [
    "#### Try out the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4625fdc0-c6ef-4dcf-bbc0-d250a0ed277c",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'country support'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistral(\n",
    "    response.format(\n",
    "        inquiry=\"I am inquiring about the availability of your cards in the EU\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4252e995-f3fc-4e62-abdb-3e367df55cbe",
   "metadata": {},
   "source": [
    "## Information Extraction with JSON Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6741a613-5b1b-4fb1-9843-1c5737f36cd5",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "medical_notes = \"\"\"\n",
    "A 60-year-old male patient, Mr. Johnson, presented with symptoms\n",
    "of increased thirst, frequent urination, fatigue, and unexplained\n",
    "weight loss. Upon evaluation, he was diagnosed with diabetes,\n",
    "confirmed by elevated blood sugar levels. Mr. Johnson's weight\n",
    "is 210 lbs. He has been prescribed Metformin to be taken twice daily\n",
    "with meals. It was noted during the consultation that the patient is\n",
    "a current smoker. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14c2bd7a-48c9-4c0b-8a4a-049a43045805",
   "metadata": {
    "height": 472
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Extract information from the following medical notes:\n",
    "{medical_notes}\n",
    "\n",
    "Return json format with the following JSON schema: \n",
    "\n",
    "{{\n",
    "        \"age\": {{\n",
    "            \"type\": \"integer\"\n",
    "        }},\n",
    "        \"gender\": {{\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"male\", \"female\", \"other\"]\n",
    "        }},\n",
    "        \"diagnosis\": {{\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"migraine\", \"diabetes\", \"arthritis\", \"acne\"]\n",
    "        }},\n",
    "        \"weight\": {{\n",
    "            \"type\": \"integer\"\n",
    "        }},\n",
    "        \"smoking\": {{\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"yes\", \"no\"]\n",
    "        }}\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "951a0b58-aae5-45e2-8496-714b884f16b6",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"age\": 60,\n",
      "  \"gender\": \"male\",\n",
      "  \"diagnosis\": \"diabetes\",\n",
      "  \"weight\": 210,\n",
      "  \"smoking\": \"yes\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = mistral(prompt, is_json=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a9cb95-bb08-4929-b16c-eb19877f3c01",
   "metadata": {},
   "source": [
    "## Personalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cf048b4-3e33-4753-af97-25b73c51ee6a",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "email = \"\"\"\n",
    "Dear mortgage lender, \n",
    "\n",
    "What's your 30-year fixed-rate APR, how is it compared to the 15-year \n",
    "fixed rate?\n",
    "\n",
    "Regards,\n",
    "Anna\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36de7c1e-60c2-4f35-a51a-115b12d65bb6",
   "metadata": {
    "height": 404
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "\n",
    "You are a mortgage lender customer service bot, and your task is to \n",
    "create personalized email responses to address customer questions.\n",
    "Answer the customer's inquiry using the provided facts below. Ensure \n",
    "that your response is clear, concise, and directly addresses the \n",
    "customer's question. Address the customer in a friendly and \n",
    "professional manner. Sign the email with \"Lender Customer Support.\"   \n",
    "      \n",
    "# Facts\n",
    "30-year fixed-rate: interest rate 6.403%, APR 6.484%\n",
    "20-year fixed-rate: interest rate 6.329%, APR 6.429%\n",
    "15-year fixed-rate: interest rate 5.705%, APR 5.848%\n",
    "10-year fixed-rate: interest rate 5.500%, APR 5.720%\n",
    "7-year ARM: interest rate 7.011%, APR 7.660%\n",
    "5-year ARM: interest rate 6.880%, APR 7.754%\n",
    "3-year ARM: interest rate 6.125%, APR 7.204%\n",
    "30-year fixed-rate FHA: interest rate 5.527%, APR 6.316%\n",
    "30-year fixed-rate VA: interest rate 5.684%, APR 6.062%\n",
    "\n",
    "# Email\n",
    "{email}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaf50774-0f91-4e0e-86c9-1525f6045ebb",
   "metadata": {
    "height": 47,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Anna,\n",
      "\n",
      "Thank you for reaching out to us.\n",
      "\n",
      "Our 30-year fixed-rate APR is currently 6.484%. In comparison, the 15-year fixed-rate APR is 5.848%. This means that the 15-year fixed-rate option has a lower APR, which could result in paying less interest over the life of the loan, but the monthly payments would be higher due to the shorter term.\n",
      "\n",
      "If you have any more questions or need further assistance, please feel free to ask.\n",
      "\n",
      "Best regards,\n",
      "Lender Customer Support.\n"
     ]
    }
   ],
   "source": [
    "response = mistral(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfaad2c-411e-4221-80f0-7acd21ba398c",
   "metadata": {},
   "source": [
    "## Summarization\n",
    "\n",
    "- We'll use this [article](https://www.deeplearning.ai/the-batch/mistral-enhances-ai-landscape-in-europe-with-microsoft-partnership-and-new-language-models) from The Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bbab492-1d18-4832-86a9-2fba645e0e52",
   "metadata": {
    "height": 336
   },
   "outputs": [],
   "source": [
    "newsletter = \"\"\"\n",
    "European AI champion Mistral AI unveiled new large language models and formed an alliance with Microsoft. \n",
    "\n",
    "What’s new: Mistral AI introduced two closed models, Mistral Large and Mistral Small (joining Mistral Medium, which debuted quietly late last year). Microsoft invested $16.3 million in the French startup, and it agreed to distribute Mistral Large on its Azure platform and let Mistral AI use Azure computing infrastructure. Mistral AI makes the new models available to try for free here and to use on its La Plateforme and via custom deployments.\n",
    "\n",
    "Model specs: The new models’ parameter counts, architectures, and training methods are undisclosed. Like the earlier, open source Mistral 7B and Mixtral 8x7B, they can process 32,000 tokens of input context. \n",
    "\n",
    "Mistral Large achieved 81.2 percent on the MMLU benchmark, outperforming Anthropic’s Claude 2, Google’s Gemini Pro, and Meta’s Llama 2 70B, though falling short of GPT-4. Mistral Small, which is optimized for latency and cost, achieved 72.2 percent on MMLU.\n",
    "Both models are fluent in French, German, Spanish, and Italian. They’re trained for function calling and JSON-format output.\n",
    "Microsoft’s investment in Mistral AI is significant but tiny compared to its $13 billion stake in OpenAI and Google and Amazon’s investments in Anthropic, which amount to $2 billion and $4 billion respectively.\n",
    "Mistral AI and Microsoft will collaborate to train bespoke models for customers including European governments.\n",
    "Behind the news: Mistral AI was founded in early 2023 by engineers from Google and Meta. The French government has touted the company as a home-grown competitor to U.S.-based leaders like OpenAI. France’s representatives in the European Commission argued on Mistral’s behalf to loosen the European Union’s AI Act oversight on powerful AI models. \n",
    "\n",
    "Yes, but: Mistral AI’s partnership with Microsoft has divided European lawmakers and regulators. The European Commission, which already was investigating Microsoft’s agreement with OpenAI for potential breaches of antitrust law, plans to investigate the new partnership as well. Members of President Emmanuel Macron’s Renaissance party criticized the deal’s potential to give a U.S. company access to European users’ data. However, other French lawmakers support the relationship.\n",
    "\n",
    "Why it matters: The partnership between Mistral AI and Microsoft gives the startup crucial processing power for training large models and greater access to potential customers around the world. It gives the tech giant greater access to the European market. And it gives Azure customers access to a high-performance model that’s tailored to Europe’s unique regulatory environment.\n",
    "\n",
    "We’re thinking: Mistral AI has made impressive progress in a short time, especially relative to the resources at its disposal as a startup. Its partnership with a leading hyperscaler is a sign of the tremendous processing and distribution power that remains concentrated in the large, U.S.-headquartered cloud companies.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaede63d-7392-4f1c-8a87-507ee31fe246",
   "metadata": {
    "height": 472
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a commentator. Your task is to write a report on a newsletter. \n",
    "When presented with the newsletter, come up with interesting questions to ask,\n",
    "and answer each question. \n",
    "Afterward, combine all the information and write a report in the markdown\n",
    "format. \n",
    "\n",
    "# Newsletter: \n",
    "{newsletter}\n",
    "\n",
    "# Instructions: \n",
    "## Summarize:\n",
    "In clear and concise language, summarize the key points and themes \n",
    "presented in the newsletter.\n",
    "\n",
    "## Interesting Questions: \n",
    "Generate three distinct and thought-provoking questions that can be \n",
    "asked about the content of the newsletter. For each question:\n",
    "- After \"Q: \", describe the problem \n",
    "- After \"A: \", provide a detailed explanation of the problem addressed \n",
    "in the question.\n",
    "- Enclose the ultimate answer in <>.\n",
    "\n",
    "## Write a analysis report\n",
    "Using the summary and the answers to the interesting questions, \n",
    "create a comprehensive report in Markdown format. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5505b0a5-411b-4804-aaef-ccecfa3d07be",
   "metadata": {
    "height": 47,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Summary\n",
      "\n",
      "Mistral AI, a European AI startup, has introduced two new large language models, Mistral Large and Mistral Small, and formed a strategic alliance with Microsoft. Microsoft invested $16.3 million in Mistral AI, agreeing to distribute Mistral Large on its Azure platform and provide computing infrastructure. The new models are available for free trials and can process 32,000 tokens of input context. Mistral Large outperformed several competitors on the MMLU benchmark but fell short of GPT-4. Both models are multilingual and optimized for function calling and JSON-format output. The partnership has sparked debate among European lawmakers and regulators, with concerns about data privacy and antitrust issues. The collaboration aims to train bespoke models for European governments and customers, leveraging Microsoft's processing power and Mistral AI's expertise.\n",
      "\n",
      "## Interesting Questions\n",
      "\n",
      "### Q: How does Mistral AI's performance on the MMLU benchmark compare to other leading models, and what implications does this have for the AI industry?\n",
      "\n",
      "**A:** Mistral AI's Mistral Large model achieved an 81.2% score on the MMLU benchmark, outperforming models like Anthropic’s Claude 2, Google’s Gemini Pro, and Meta’s Llama 2 70B, but falling short of GPT-4. This performance indicates that Mistral AI is competitive with other leading AI models despite being a relatively new player in the industry. The implications are significant: Mistral AI's success suggests that European AI startups can compete with U.S.-based giants, potentially shifting the balance of power in the AI industry. This could also encourage more investment and innovation in European AI, fostering a more diverse and competitive global AI landscape.\n",
      "\n",
      "### Q: What are the potential benefits and drawbacks of Mistral AI's partnership with Microsoft for European users and regulators?\n",
      "\n",
      "**A:** The partnership between Mistral AI and Microsoft offers several benefits, including access to high-performance models tailored to Europe's regulatory environment, enhanced processing power for training large models, and greater access to potential customers worldwide. However, there are also potential drawbacks. European lawmakers and regulators have expressed concerns about data privacy and antitrust issues, as the partnership could give Microsoft access to European users' data. This has led to investigations by the European Commission, which is already scrutinizing Microsoft's agreement with OpenAI. The partnership could also be seen as a potential monopoly, raising concerns about market dominance and competition.\n",
      "\n",
      "### Q: How does Mistral AI's rapid progress and partnership with Microsoft reflect broader trends in the AI industry?\n",
      "\n",
      "**A:** Mistral AI's rapid progress and partnership with Microsoft reflect several broader trends in the AI industry. First, it highlights the growing importance of strategic alliances between startups and established tech giants, which can provide startups with the resources and infrastructure needed to scale quickly. Second, it underscores the concentration of processing and distribution power in large, U.S.-headquartered cloud companies, which can significantly influence the AI landscape. Finally, it reflects the increasing competition and innovation in the AI industry, with European startups emerging as strong contenders against U.S.-based leaders.\n",
      "\n",
      "## Analysis Report\n",
      "\n",
      "# Mistral AI and Microsoft Partnership: A New Era in European AI\n",
      "\n",
      "Mistral AI, a European AI startup, has made significant strides in the AI industry by introducing two new large language models, Mistral Large and Mistral Small, and forming a strategic alliance with Microsoft. This partnership, backed by a $16.3 million investment from Microsoft, aims to leverage Microsoft's Azure platform for distributing Mistral Large and providing computing infrastructure. The new models are available for free trials and can process 32,000 tokens of input context, showcasing Mistral AI's commitment to innovation and accessibility.\n",
      "\n",
      "## Model Performance and Multilingual Capabilities\n",
      "\n",
      "Mistral AI's Mistral Large model achieved an impressive 81.2% score on the MMLU benchmark, outperforming several leading models but falling short of GPT-4. This performance highlights Mistral AI's competitive edge in the AI industry, despite being a relatively new player. Both models are fluent in French, German, Spanish, and Italian, and are optimized for function calling and JSON-format output, making them versatile tools for various applications.\n",
      "\n",
      "## Strategic Partnership and Regulatory Concerns\n",
      "\n",
      "The partnership between Mistral AI and Microsoft offers numerous benefits, including access to high-performance models tailored to Europe's regulatory environment, enhanced processing power, and greater market reach. However, it has also sparked debate among European lawmakers and regulators, who have expressed concerns about data privacy and antitrust issues. The European Commission is investigating the partnership, adding to the scrutiny already faced by Microsoft's agreement with OpenAI.\n",
      "\n",
      "## Broader Industry Trends\n",
      "\n",
      "Mistral AI's rapid progress and partnership with Microsoft reflect broader trends in the AI industry, including the growing importance of strategic alliances, the concentration of processing power in large cloud companies, and the increasing competition and innovation in the AI landscape. This partnership could potentially shift the balance of power in the AI industry, fostering a more diverse and competitive global AI ecosystem.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "The partnership between Mistral AI and Microsoft is a significant development in the AI industry, offering both opportunities and challenges. While it provides Mistral AI with the resources and infrastructure needed to scale quickly, it also raises concerns about data privacy and market dominance. As the AI industry continues to evolve, partnerships like this will play a crucial role in shaping its future, and it will be essential for regulators to ensure that these collaborations benefit users and promote fair competition.\n"
     ]
    }
   ],
   "source": [
    "response = mistral(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6590c2-2558-45be-84cb-b1b99dbc3776",
   "metadata": {},
   "source": [
    "#### Try it out for yourself\n",
    "- Feel free to copy-paste text from another article in The Batch, or any other blog or news article."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed88147-8d43-4207-b45b-06543371f913",
   "metadata": {},
   "source": [
    "## The Mistral Python client\n",
    "- Below is the helper function that you imported from helper.py and used earlier in this notebook.\n",
    "- For more details, check out the [Mistral AI API documentation](https://docs.mistral.ai/api/)\n",
    "- To get your own Mistral AI API key to use on your own, outside of this classroom, you can create an account and go to the [console](https://console.mistral.ai/) to subscribe and create an API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27ef7a7f-ebd6-49c3-8f91-5f5d284edf17",
   "metadata": {
    "height": 353
   },
   "outputs": [],
   "source": [
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage   \n",
    "\n",
    "def mistral(user_message, \n",
    "            model=\"mistral-small-latest\",\n",
    "            is_json=False):\n",
    "    client = MistralClient(api_key=os.getenv(\"MISTRAL_API_KEY\"))\n",
    "    messages = [ChatMessage(role=\"user\", content=user_message)]\n",
    "\n",
    "    if is_json:\n",
    "        chat_response = client.chat(\n",
    "            model=model, \n",
    "            messages=messages,\n",
    "            response_format={\"type\": \"json_object\"})\n",
    "    else:\n",
    "        chat_response = client.chat(\n",
    "            model=model, \n",
    "            messages=messages)\n",
    "        \n",
    "    return chat_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd279d2-d4cd-4465-9d65-8143a16c4bca",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
